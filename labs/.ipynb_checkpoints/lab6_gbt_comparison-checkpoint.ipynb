{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab we'll get some experience tuning a Gradient Boosted Tree classifier and then compare classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# California Housing Prices Dataset\n",
    "For this lab we'll use a [dataset](https://www.kaggle.com/camnugent/california-housing-prices/data) on houses from California. Download it and place it in your lab data directory. Before we proceed to doing any kind of learning on the dataset, use some of the visualization functions you wrote for your machine elarning pipeline in assignment 2.\n",
    "\n",
    "Dataset: https://www.kaggle.com/camnugent/california-housing-prices/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value ocean_proximity  \n",
       "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
       "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
       "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
       "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
       "4       565.0       259.0         3.8462            342200.0        NEAR BAY  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname = 'housing.csv'\n",
    "df = pd.read_csv(fname)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most natural thing to do with this dataset is to create a model to predict housing price given the other features. But since we've mostly only discussed classification, we'll instead try to build a model that predicts the ocean_proximity column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Count')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9b678fc6d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df['ocean_proximity'])\n",
    "plt.title('Frequency of house locations')\n",
    "plt.xlabel('House location')\n",
    "plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Do any sort of necessary preprocessing like handling missing data, dealing with outliers, etc. Your code from homework 2 might be useful here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
       "       'total_bedrooms', 'population', 'households', 'median_income',\n",
       "       'median_house_value', 'ocean_proximity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_nulls(df):\n",
    "\treturn df.isna().sum().sort_values(ascending=False)\n",
    "\n",
    "def fill_whole_df_with_mean(df):\n",
    "    num_cols = len(df.columns)\n",
    "    for i in range(0, num_cols):\n",
    "        df.iloc[:,i] = fill_col_with_mean(df.iloc[:,i])\n",
    "    return\n",
    "\n",
    "def fill_col_with_mean(df):\n",
    "\treturn df.fillna(df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "total_bedrooms        207\n",
       "ocean_proximity         0\n",
       "median_house_value      0\n",
       "median_income           0\n",
       "households              0\n",
       "population              0\n",
       "total_rooms             0\n",
       "housing_median_age      0\n",
       "latitude                0\n",
       "longitude               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_nulls(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['total_bedrooms'] = fill_col_with_mean(df['total_bedrooms'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ocean_proximity       0\n",
       "median_house_value    0\n",
       "median_income         0\n",
       "households            0\n",
       "population            0\n",
       "total_bedrooms        0\n",
       "total_rooms           0\n",
       "housing_median_age    0\n",
       "latitude              0\n",
       "longitude             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_nulls(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Visualize the distributions of each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Split the data into a train/test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split \n",
    "def split_traintest(df_features, df_target, test_size = 0.2):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(df_features, df_target, test_size = test_size)\n",
    "    return X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_list = ['housing_median_age', 'total_rooms',\n",
    "       'total_bedrooms', 'population', 'households', 'median_income','ocean_proximity']\n",
    "df_features = df[features_list]\n",
    "df_target = df['median_house_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = split_traintest(df_features, df_target, 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Gradient Boosted Trees\n",
    "Last week we discussed boosting in class. Gradient Boosted Trees is a model that uses shallow decision trees in conjunction with boosting to create a model with low bias(ideally). Recall the bias-variance tradeoff from lab last week. Fully grown decision trees have low bias but high variance; random forests aggregates a collection of decision trees to get a classifier that has low bias and low variance. On the otherhand, shallow decision trees have high(er) bias and low(er) variance. With boosting, we learn a collection of shallow decision trees in an iterative manner to reduce our training error; each tree tries to fit the residual error from the trees learned at earlier stages of the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GBT Parameters\n",
    "The parameters in sklearn's [GradientBoostingClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html) are mostly the same as those for the Decision Trees/[RandomForestsClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) with the exception of learning rate(determines how much to subsequent trees in the ensemble) and n_estimators.\n",
    "Random Forests also had an n_estimators parameter. But recall in RF, increasing n_estimators will almost always improve your ability to generalize to unseen data(similar to how sampling more of a population will give you a better estimate of the population mean). However, in Gradient Boosted Trees, each tree is fit to predict the error produced by the previously built trees. If n_estimators is too high, the resulting Gradient Boosted Tree may overfit, so you need to use cross validation to determine the optimal value.\n",
    "\n",
    "The other parameters are:\n",
    "* loss : {‘deviance’, ‘exponential’}, optional (default=’deviance’)\n",
    "loss function to be optimized. ‘deviance’ refers to deviance (= logistic regression) for classification with p robabilistic outputs. For loss ‘exponential’ gradient boosting recovers the AdaBoost algorithm.\n",
    "* learning_rate : float, optional (default=0.1)\n",
    "learning rate shrinks the contribution of each tree by learning_rate.\n",
    "* n_estimators : int (default=100) The number of boosting stages to perform. Gradient boosting is fairly robust to over-fitting so a large number usually results in better performance.\n",
    "\n",
    "The remaining parameters are parameters for decision trees. You should spend some time thinking about the effects of each parameter. What happens if you set them too high or too low?\n",
    "* max_depth: if this is too high you'll overfit, too low and you'll underfit\n",
    "* min_samples_split: higher values control against overfitting\n",
    "* min_samples_leaf: higher values control against overfitting\n",
    "* max_features: higher values can lead to overfitting\n",
    "* max_leaf_nodes: lower values restrict the growth of the tree and which control against overfitting\n",
    "* min_impurity_decrease : float, optional (default=0.) A node will be split if this split induces a decrease of the impurity greater than or equal to this value. If this is too high, the learned tree will be more conservative with splitting nodes and possibly underfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validating these parameters\n",
    "3) Pick a few values for each of these parameters to use for cross validation. Since there are so many parameters, and we don't want to be waiting forever for the cross validation results, you can fix a few of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = ['deviance', 'exponential']\n",
    "learning_rate =  [0.01, 0.1, 0.2, 0.3]\n",
    "n_estimators = [3,6,10,20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "4) Write a function to do the cross validation using GridSearchCV. It might be helpful to revisit the code from last weeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_cv(clf, param_grid, scoring, cv, x_train, y_train):\n",
    "    # initialize the grid, scoring = a scoring metric or a dictionary of metrics, \n",
    "    # refit is necessary when u have a list of scoring metrics, it determines how the gridsearch algorithm decides the best estimator.\n",
    "    grid = GridSearchCV(clf(), param_grid, scoring = scoring, cv= cv)\n",
    "    grid.fit(x_train, y_train)\n",
    "\n",
    "    # call the best classifier:\n",
    "    grid.best_estimator_\n",
    "\n",
    "    # see all performances:\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = {'learning rate': learning_rate, 'n_est': n_estimators}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(GradientBoostingClassifier(), param_grid, scoring = 'f1', cv= 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiangyu/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter learning rate for estimator GradientBoostingClassifier(criterion='friedman_mse', init=None,\n              learning_rate=0.1, loss='deviance', max_depth=3,\n              max_features=None, max_leaf_nodes=None,\n              min_impurity_decrease=0.0, min_impurity_split=None,\n              min_samples_leaf=1, min_samples_split=2,\n              min_weight_fraction_leaf=0.0, n_estimators=100,\n              presort='auto', random_state=None, subsample=1.0, verbose=0,\n              warm_start=False). Check the list of available parameters with `estimator.get_params().keys()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-240017669b03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0mtrain_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mset_params\u001b[0;34m(self, **params)\u001b[0m\n\u001b[1;32m    272\u001b[0m                                  \u001b[0;34m'Check the list of available parameters '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m                                  \u001b[0;34m'with `estimator.get_params().keys()`.'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m                                  (key, self))\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdelim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid parameter learning rate for estimator GradientBoostingClassifier(criterion='friedman_mse', init=None,\n              learning_rate=0.1, loss='deviance', max_depth=3,\n              max_features=None, max_leaf_nodes=None,\n              min_impurity_decrease=0.0, min_impurity_split=None,\n              min_samples_leaf=1, min_samples_split=2,\n              min_weight_fraction_leaf=0.0, n_estimators=100,\n              presort='auto', random_state=None, subsample=1.0, verbose=0,\n              warm_start=False). Check the list of available parameters with `estimator.get_params().keys()`."
     ]
    }
   ],
   "source": [
    "grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Evaluate the best model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test set evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Plot the confusion matrix for the test set. Which classes are most difficult to predict?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, we're just interested in finding a _some model_ that performs the best for whatever problem we're trying to solve. In the past few weeks we've seen a bunch of classifiers:\n",
    "* K Nearest Neighbors\n",
    "* Decision Trees\n",
    "* Logistic Regression\n",
    "* SVM\n",
    "* Naive Bayes\n",
    "* Random Forests\n",
    "* Gradient Boosted Trees\n",
    "It's hard to know which classifier is best suited for the problem you're trying to solve without getting your hands dirty and just doing the classification. So let's write a function to fit/evaluate the classifiers we're interested in!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Change the function you wrote for cross validating GBT to allow you to do that cross validation for a collection of classifiers(along with their own set of parameters to cross validate over) or fill in the function template below.\n",
    "\n",
    "It might be helpful to define dictionaries that map sklearn models to their param grid dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cv_evaluation(model_params, x_train, x_test, y_train, y_test):\n",
    "    '''\n",
    "    Given a dictionary of classifiers mapped to parameter grids to cross validate over, this\n",
    "    function run cross validation for each (classifier, parameter grid) combination and returns the best\n",
    "    estimator of each type of classifier\n",
    "    Args:\n",
    "        model_params: dict mapping sklearn model to parameter grid dictionary\n",
    "    Returns:\n",
    "        a 2-tuple containing:\n",
    "            DataFrame containing cross validation results\n",
    "            list/dictionary/or whatever containing the best estimator of each classifier\n",
    "    '''\n",
    "\n",
    "    for model, param_grid in model_params.items():\n",
    "        # do stuff with GridSearchCV\n",
    "        pass\n",
    "    \n",
    "    # return something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# note that the parameter grid dictionary keys should match the spelling of the parameter of the sklearn model\n",
    "model_params = {\n",
    "    LogisticRegression: {'C': [10**i for i in range(-2, 3)], 'penalty': ['l1, l2']}, \n",
    "    KNeighborsClassifier: {'n_neighbors': [i for i in range(1, 9)]},\n",
    "}\n",
    "\n",
    "# x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
    "cv_results, best_classifiers = cv_evaluation(model_params, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) does most of this work for you. Here are some of the potentially useful attributes/functions of the GridSearchCV class:\n",
    "* cv\\_results\n",
    "* best\\_estimator\\_\n",
    "* best\\_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) Which models performed the best? Are you surprised by the results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find best performing classifiers from GridSearchCV results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
